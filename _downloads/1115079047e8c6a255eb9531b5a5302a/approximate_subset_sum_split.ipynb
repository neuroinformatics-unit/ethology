{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Split an annotations dataset\n\nSplit an annotations dataset by grouping variable, and compare to random\nsplitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This example demonstrates two dataset splitting strategies:\n\n- **Grouping-based split**: splits the input dataset into two subsets with\n  approximately the requested fractions, while keeping the values of a\n  user-defined grouping variable (such as \"videos\" or \"species\") entirely\n  separate between subsets. We will explore two approaches: a group k-fold\n  approach and an approximate subset-sum approach.\n\n- **Random split**: splits the input dataset randomly into subsets with\n  the requested fractions. It achieves precise split fractions but may mix\n  values of variables across subsets (e.g., frames from the same video\n  may be present in multiple subsets).\n\nA grouping-based split is useful when defining a held-out test dataset\nwith a specified percentage. For example, you may want to hold out ~10%\nof the annotated frames while ensuring that frames from the same video are\nnot present in both the training and test sets.\n\nIn contrast, a random splitting strategy divides the dataset into precise\nproportions but does not prevent data leakage across subsets. This may be\nuseful, for example, to generate multiple train/validation\nsplits with very similar content for\n[cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)).\n\nBoth approaches can be useful in different situations, and this example\ndemonstrates how to apply them using ``ethology``.\n\nFor more complex dataset splits, we recommend going through [scikit-learn's\ncross-validation functionalities](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-evaluating-estimator-performance),\nin particular the section on [grouped data](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators-for-grouped-data).\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import sys\nfrom collections import Counter\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pooch\nimport xarray as xr\nfrom loguru import logger\n\nfrom ethology.datasets.split import (\n    split_dataset_group_by,\n    split_dataset_random,\n)\nfrom ethology.io.annotations import load_bboxes\n\n# For interactive plots: install ipympl with `pip install ipympl` and uncomment\n# the following line in your notebook\n# %matplotlib widget"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure logging for this example\nBy default, ``ethology`` outputs log messages to ``stderr``. Here,\nwe configure the logger to output logs to ``stdout`` as well, so that\nwe can display the log messages produced in this example.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_ = logger.add(sys.stdout, level=\"INFO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download dataset\nFor this example, we will use the [Australian Camera Trap Dataset](https://figshare.com/articles/dataset/Australian_Camera_Trap_Data_ACTD_/27177912)\nwhich comprises images from camera traps across various sites in Victoria,\nAustralia.\n\nWe use the [pooch](https://github.com/fatiando/pooch/) library to download\nthe dataset to the ``.ethology`` cache directory.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_source = {\n    \"url\": \"https://figshare.com/ndownloader/files/53674187\",\n    \"hash\": \"4019bb11cd360d66d13d9309928195638adf83e95ddec7b0b23e693ec8c7c26b\",\n}\n\n# Define cache directory\nethology_cache = Path.home() / \".ethology\"\nethology_cache.mkdir(exist_ok=True)\n\n# Download the dataset to the cache directory\nextracted_files = pooch.retrieve(\n    url=data_source[\"url\"],\n    known_hash=data_source[\"hash\"],\n    fname=\"ACTD_COCO_files.zip\",\n    path=ethology_cache,\n    processor=pooch.Unzip(extract_dir=ethology_cache / \"ACTD_COCO_files\"),\n)\n\nprint(*extracted_files, sep=\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read as a single annotation dataset\n\nThe dataset contains three different COCO annotation files. We can load them\nas a single dataset using the\n:func:`ethology.io.annotations.load_bboxes.from_files`\nfunction.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ds_all = load_bboxes.from_files(extracted_files, format=\"COCO\")\n\nprint(ds_all)\nprint(*ds_all.annotation_files, sep=\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspect dataset\n\nThe combined dataset contains annotations for 39426 images,\nwith each image having a maximum of 6 annotations. We can further inspect\nthe different categories considered, the image sizes and the format of the\nimage filenames.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Categories\nprint(\"Categories:\")\nprint(ds_all.map_category_to_str.values())\nprint(\"--------------------------------\")\n\n# Image sizes\nprint(\"Image sizes:\")\nprint(np.unique(ds_all.image_shape.values, axis=0))\nprint(\"--------------------------------\")\n\n# Print a few image filenames\nprint(\"Sample image filenames:\")\nprint(list(ds_all.map_image_id_to_filename.values())[0])\nprint(list(ds_all.map_image_id_to_filename.values())[30000])\nprint(list(ds_all.map_image_id_to_filename.values())[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The image filenames encode a bit more of extra information, such\nas the original annotation file or the species class. We can use\nthis to define possible grouping variables to split the images in\nthe dataset.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split by species: group k-fold approach\nLet's assume we want to split the dataset into two sets,\nsuch that each set has distinct species. This may be useful for\nexample, if we want to evaluate the\n[zero-shot](https://en.wikipedia.org/wiki/Zero-shot_learning) performance\nof a species classifier, that is, its performance on species not seen during\ntraining. In this case we may want to split the dataset into train and test\nsets, while ensuring that no species are present in both train and test sets.\n\nTo do this, we first need to compute a variable that holds the species\nper image. Then we can split the images in the dataset based on\nthe species they contain. Note that only one specie is defined per\nimage.\n\nWe use a helper function to extract the information of interest\nfrom the image filenames.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Helper function\ndef split_at_any_delimiter(text: str, delimiters: list[str]) -> list[str]:\n    \"\"\"Split a string at any of the specified delimiters if present.\"\"\"\n    for delimiter in delimiters:\n        if delimiter in text:\n            return text.split(delimiter)\n    return [text]\n\n\n# Get species name per image\nspecies_per_image_id = np.array(\n    [\n        ds_all.map_image_id_to_filename[i].split(\"\\\\\")[-2]\n        for i in ds_all.image_id.values\n    ]\n)\n\n# Add the species array to the dataset\nds_all[\"specie\"] = xr.DataArray(\n    species_per_image_id,\n    dims=\"image_id\",\n)\n\nprint(f\"Total species: {len(np.unique(species_per_image_id))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have 15 different species in the dataset. With a bar plot we can visualise\ntheir distribution in the dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "count_per_specie = dict(Counter(ds_all[\"specie\"].values).most_common())\n\nfig, ax = plt.subplots()\nax.bar(\n    count_per_specie.keys(),\n    count_per_specie.values(),\n)\nax.set_xticks(range(len(count_per_specie)))\nax.set_xticklabels(count_per_specie.keys(), rotation=90)\nax.set_ylabel(\"# images\")\nax.set_title(\"Image count per specie\")\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now split the dataset by species using the\n:func:`ethology.datasets.split.split_dataset_group_by`\nfunction. For example, for a very specific 30/70 split,\nwe would do:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fraction_1 = 0.3\nfraction_2 = 1 - fraction_1\n\nds_species_1, ds_species_2 = split_dataset_group_by(\n    ds_all,\n    group_by_var=\"specie\",\n    list_fractions=[fraction_1, fraction_2],\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By default, the ``method`` parameter of the function is set to ``auto``,\nwhich automatically selects the appropriate splitting method based on the\nnumber of unique groups and the requested split fractions. From the info\nmessages logged to the terminal we can see that the automatically selected\nmethod was the \"group k-fold\" method. To force the use of this method, we\ncan explicitly set the ``method`` parameter of the function to ``kfold``.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can check how close is the resulting split to the\nrequested fractions, and verify that the subsets contain distinct species.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"User specified fractions:{[fraction_1, fraction_2]}\")\n\nprint(\n    \"Output split fractions: [\"\n    f\"{len(ds_species_1.image_id.values) / len(ds_all.image_id.values):.3f}, \"\n    f\"{len(ds_species_2.image_id.values) / len(ds_all.image_id.values):.3f}]\"\n)\n\nprint(\"--------------------------------\")\nprint(f\"Subset 1 species: {np.unique(ds_species_1.specie.values)}\")\nprint(f\"Subset 2 species: {np.unique(ds_species_2.specie.values)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When using the \"group k-fold\" method, we can also generate different splits\nby setting a different value for the ``seed`` parameter. In the example\nbelow, we set the ``method`` parameter to ``kfold`` and use two different\nseed values, to generate two different splits.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Split A with seed 42\nds_species_1a, ds_species_2a = split_dataset_group_by(\n    ds_all,\n    group_by_var=\"specie\",\n    list_fractions=[fraction_1, fraction_2],\n    method=\"kfold\",\n    seed=42,\n)\n\n# Split B with seed 43\nds_species_1b, ds_species_2b = split_dataset_group_by(\n    ds_all,\n    group_by_var=\"specie\",\n    list_fractions=[fraction_1, fraction_2],\n    method=\"kfold\",\n    seed=43,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can verify that the split using the default value of the ``seed``\nparameter (42) is the same as the first split computed above, but different\nfrom the split obtained with a different seed value (43). The output\nfractions in both cases are approximately the requested fractions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\n    \"Output split fractions for seed 42: [\"\n    f\"{len(ds_species_1a.image_id.values) / len(ds_all.image_id.values):.3f}, \"\n    f\"{len(ds_species_2a.image_id.values) / len(ds_all.image_id.values):.3f}]\"\n)\n\nprint(\n    \"Output split fractions for seed 43: [\"\n    f\"{len(ds_species_1b.image_id.values) / len(ds_all.image_id.values):.3f}, \"\n    f\"{len(ds_species_2b.image_id.values) / len(ds_all.image_id.values):.3f}]\"\n)\n\n\nassert ds_species_1a.equals(ds_species_1)\nassert ds_species_2a.equals(ds_species_2)\nassert not ds_species_1a.equals(ds_species_1b)\nassert not ds_species_2a.equals(ds_species_2b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have mentioned that by default, the ``method`` in the\n:func:`ethology.datasets.split.split_dataset_group_by` function is set to\n``auto``, which automatically selects\nthe appropriate method based on the number of unique groups and\nthe requested number of folds. The number of required folds is calculated as\nthe closest integer to ``1 / min(list_fractions)``.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this case, we have 15 unique species, and 1/0.3 ~ 3 folds. Since\nthere are more unique groups than folds, the the ``auto`` setting defers to\nthe preferred  \"group k-fold\" method. The \"group k-fold\" method is preferred\nbecause it allows us to compute different disjoint splits for the same\nrequested fractions via the ``seed`` parameter.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the number of unique groups is less than the requested\nnumber of folds, the ``auto`` setting defers to\n[approximate subset sum algorithm](https://en.wikipedia.org/wiki/Subset_sum_problem#Fully-polynomial_time_approximation_scheme).\nto compute a solution. We explore this case in the next section.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split by input annotation file: approximate subset-sum approach\nLet's consider another case, in which we would like to split the images in\nthe dataset by the annotation file they come from.\n\nAs before, we first compute the annotation file per image, which we\nderive from the image filename. Then we add the annotation file array to\nthe dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Get annotation file per image\nannotation_file_per_image_id = np.array(\n    [\n        split_at_any_delimiter(\n            ds_all.map_image_id_to_filename[i],\n            [\"\\\\\"],\n        )[0]\n        for i in ds_all.image_id.values\n    ]\n)\n\n# Add to dataset\nds_all[\"json_file\"] = xr.DataArray(\n    annotation_file_per_image_id, dims=\"image_id\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now split the dataset by annotation file using the\n:func:`ethology.datasets.split.split_dataset_group_by`\nfunction with the ``method`` parameter set to ``apss``\n(approximate subset-sum).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ds_annotations_1, ds_annotations_2 = split_dataset_group_by(\n    ds_all,\n    group_by_var=\"json_file\",\n    list_fractions=[fraction_1, fraction_2],\n    method=\"apss\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The log message confirms we have used the \"approximate subset-sum\" method.\nIt also mentions an ``epsilon`` parameter, which is optional. This is the\npercentage of the optimal solution that the solution is guaranteed to be\nwithin. If ``epsilon`` is 0 (default), the solution will be the best solution\n(optimal) for the requested fraction and grouping variable.\n\nThe algorithm computes the smallest subset to be less than\nor equal to the smallest requested fraction.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"User specified fractions:{[fraction_1, fraction_2]}\")\n\noutput_fractions = [\n    len(ds_annotations_1.image_id.values) / len(ds_all.image_id.values),\n    len(ds_annotations_2.image_id.values) / len(ds_all.image_id.values),\n]\nprint(f\"Output split fractions for epsilon 0: {output_fractions}\")\n\nprint(f\"Subset 1 files: {np.unique(ds_annotations_1.json_file.values)}\")\nprint(f\"Subset 2 files: {np.unique(ds_annotations_2.json_file.values)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can verify that the subsets contain distinct annotation files.\nSince we used the default ``epsilon=0``, this split is\nthe best solution we can get within the specified constraints.\nIn this case there are only three possible splits of the dataset, since\nthere are only three possible values for the source annotation file.\n\n\nThe choice of ``epsilon`` involves a trade-off\nbetween accuracy and speed. In more cases with many possible splits,\nwe may want to use a larger ``epsilon`` value, to get faster to a\nsolution that is close enough to the optimal one.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split using random sampling\nVery often we want to compute splits for a specific fraction, and\ndon't care if a grouping variable (such as \"species\" or\n\"source annotation file\") is mixed across subsets.\n\nIn this case, we can use random sampling with\nthe function\n:func:`ethology.datasets.split.split_dataset_random`.\nThis function shuffles the dataset and then partitions it\naccording to the specified fractions. By setting a different value for the\n``seed``, we can again get different splits for the same requested\nfractions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ds_species_1, ds_species_2 = split_dataset_random(\n    ds_all,\n    list_fractions=[fraction_1, fraction_2],\n    seed=42,\n)\n\n\nprint(f\"User specified fractions:{[fraction_1, fraction_2]}\")\n\nprint(\"Split fractions:\")\nprint(len(ds_species_1.image_id.values) / len(ds_all.image_id.values))\nprint(len(ds_species_2.image_id.values) / len(ds_all.image_id.values))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}